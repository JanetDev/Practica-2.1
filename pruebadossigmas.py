# -*- coding: utf-8 -*-
"""PruebadosSigmas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t2Mf5Rr1MQilQ9hLMt-KCHrvg52TLJrz

# **Práctica 2.1: Preprocesamiento de Datos**

### **Prueba dos sigmas**
"""

import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/trainTitanic.csv')
df.head(5)

import matplotlib.pyplot as plt

# Seleccionar la columna de edad de los pasajeros
columna_edad = df['Age']

# Eliminar filas con valores faltantes en la columna de edad
columna_edad = columna_edad.dropna()

# Crear un gráfico de dispersión para visualizar la edad de los pasajeros
plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura si es necesario
plt.scatter(range(len(columna_edad)), columna_edad, color='lightcoral', alpha=0.5)
plt.xlabel('Índice')
plt.ylabel('Edad')
plt.title('Gráfico de Dispersión de la Edad de los Pasajeros del Titanic')
plt.show()

import numpy as np

data = columna_edad.to_numpy()

# Calcular la media y la desviación estándar
media = np.mean(data)
desv = np.std(data)

# Definir el umbral para valores atípicos (usualmente, se utiliza 1.5 * desv)
umbral = 1.5 * desv

# Identificar valores atípicos
valores_atipicos = [x for x in columna_edad if abs(x - media) > umbral]

# Crear un gráfico de puntos para visualizar la edad de los pasajeros
plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura si es necesario
plt.scatter(range(len(columna_edad)), columna_edad, color='lightcoral', label='Edad', alpha=0.5)

# Resalta los valores atípicos en rojo
plt.scatter([columna_edad.tolist().index(valor) for valor in valores_atipicos], valores_atipicos, color='crimson', label='Valores Atípicos')

plt.xlabel('Índice')
plt.ylabel('Edad')
plt.title('Gráfico de Puntos de la Edad de los Pasajeros del Titanic')
plt.legend()
plt.show()

#Crear una versión alternativa del DataFrame sin los valores atípicos
df_sin_atipicos = df.loc[~df['Age'].isin(valores_atipicos)]

# Guardar esta versión en un archivo CSV
df_sin_atipicos.to_csv('titanic_sin_atipicos.csv', index=False)

print(df.isnull().sum())  # Muestra la cantidad de valores faltantes por columna

from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')
df_sin_atipicos['Age'] = imputer.fit_transform(df_sin_atipicos[['Age']])

df = df.drop('Cabin', axis=1)
df_sin_atipicos = df_sin_atipicos.drop('Cabin', axis=1)

imputer = SimpleImputer(strategy='most_frequent')
df_sin_atipicos['Embarked'] = imputer.fit_transform(df_sin_atipicos[['Embarked']])

print(df_sin_atipicos.isnull().sum())

mediagg = df['Age'].mean()
df['Age'].fillna(mediagg, inplace=True)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Seleccionar las características (atributos) y la variable objetivo (supervisión)
X = df[['Age', 'Fare']]  # Ejemplo: 'Age' y 'Fare' son características
y = df['Survived']  # Ejemplo: 'Survived' es la variable objetivo

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar un modelo (en este caso, un RandomForestClassifier)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluar el rendimiento del modelo
accuracy = accuracy_score(y_test, y_pred)
print("Exactitud del modelo en datos sin procesar:", accuracy)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Seleccionar las características (atributos) y la variable objetivo (supervisión)
X = df_sin_atipicos[['Age', 'Fare']]  # Ejemplo: 'Age' y 'Fare' son características
y = df_sin_atipicos['Survived']  # Ejemplo: 'Survived' es la variable objetivo

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar un modelo (en este caso, un RandomForestClassifier)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluar el rendimiento del modelo
accuracy = accuracy_score(y_test, y_pred)
print("Exactitud del modelo:", accuracy)