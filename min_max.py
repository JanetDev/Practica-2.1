# -*- coding: utf-8 -*-
"""Min_Max.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1odH6dMM7VREXZZFzLZwNz5daYy_w8Kh5

## Por Min-Max
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

import pandas as pd
df_titanic = pd.read_csv('/content/drive/MyDrive/trainTitanic.csv')

df_titanic.head(10)

"""## Graficamos para saber si hay valores atipicos"""

import matplotlib.pyplot as plt

# Elejimos las columnas 'Fare' y 'Age'
data = df_titanic[['Fare', 'Age']]

# Creamos un diagrama de caja
plt.figure(figsize=(8, 6))
data.boxplot(column=['Fare', 'Age'])
plt.title('Diagrama de Caja de Fare y Age')
plt.ylabel('Valores')
plt.show()

"""## Funcion para la normalización por min-max"""

def min_max(df, columna1, columna2):
    # Obtenemos los mínimos y máximos para ambas columnas
    min_val1 = df[columna1].min()
    max_val1 = df[columna1].max()

    min_val2 = df[columna2].min()
    max_val2 = df[columna2].max()

    # Normalizamos ambas columnas
    df['columna1_normalizada'] = (df[columna1] - min_val1) / (max_val1 - min_val1)
    df['columna2_normalizada'] = (df[columna2] - min_val2) / (max_val2 - min_val2)

    return df

"""## Saber si sigue una distribucion normal para Age"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(data=df_titanic, x='Age', kde=True)
plt.show()

"""## Saber si sigue una distribucion normal para Fare"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(data=df_titanic, x='Fare', kde=True)
plt.show()

"""## Pasamos la columna a la función"""

df = min_max(df_titanic, 'Age', 'Fare')

"""## Imprimimos el datafraame"""

df

print(df_titanic.isnull().sum())

"""## Reemplzamos los valores nulos por la media"""

import pandas as pd

mean_age = df_titanic['Age'].mean()

df_titanic['Age'].fillna(mean_age, inplace=True)


mean_age = df_titanic['columna1_normalizada'].mean()

df_titanic['columna1_normalizada'].fillna(mean_age, inplace=True)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Seleccionar las características
X = df_titanic[['Age', 'Fare']]
y = df_titanic['Survived']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar un modelo (en este caso, un RandomForestClassifier)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluar el rendimiento del modelo
accuracy = accuracy_score(y_test, y_pred)
print("Exactitud del modelo:", accuracy)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

X = df_titanic[['columna1_normalizada', 'columna2_normalizada']]
y = df_titanic['Survived']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear y entrenar un modelo (en este caso, un RandomForestClassifier)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluar el rendimiento del modelo
accuracy = accuracy_score(y_test, y_pred)
print("Exactitud del modelo:", accuracy)

